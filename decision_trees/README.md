# Î”Î­Î½Ï„ÏÎ± Î‘Ï€Î¿Ï†Î¬ÏƒÎµÏ‰Î½ (ÎšÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¯Î·ÏƒÎ·)

Î‘Ï…Ï„ÏŒ Ï„Î¿ module Ï€Î±ÏÎ¿Ï…ÏƒÎ¹Î¬Î¶ÎµÎ¹ Ï„Î· Ï‡ÏÎ®ÏƒÎ· **Î´Î­Î½Ï„ÏÏ‰Î½ Î±Ï€Î¿Ï†Î¬ÏƒÎµÏ‰Î½** (decision tree classifiers)
Î³Î¹Î± ÎµÏ€Î¿Ï€Ï„ÎµÏ…ÏŒÎ¼ÎµÎ½Î· Î¼Î¬Î¸Î·ÏƒÎ· (supervised learning) Î¼Îµ Ï„Î· Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· scikit-learn.

### Î£Ï„ÏŒÏ‡Î¿Î¹

- ÎšÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Ï„Î·Ï‚ Î»Î¿Î³Î¹ÎºÎ®Ï‚ Ï„Ï‰Î½ Î´Î­Î½Ï„ÏÏ‰Î½ Î±Ï€Î¿Ï†Î¬ÏƒÎµÏ‰Î½ (C4.5 / CART).
- Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÏÎ½ Î¼Î­Ï„ÏÏ‰Î½ ÎºÎ±Î¸Î±ÏÏŒÏ„Î·Ï„Î±Ï‚ ÎºÏŒÎ¼Î²Ï‰Î½:
  - **Entropy (Information Gain)**
  - **Gini Index**
  - **Gain Ratio** (Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ ÏƒÏ„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î¼Îµ Ï„Î± Î¼Î±Î½Î¹Ï„Î¬ÏÎ¹Î±)
- Î•Ï€Î¯Î´ÏÎ±ÏƒÎ· Ï„Î·Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï… `max_depth` (Overfitting / Underfitting).
- Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¹ÎºÏÎ½ ÎºÎ±Î¹ Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÏÎ½ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ (One-Hot Encoding).

---

## ğŸ“ Î‘ÏÏ‡ÎµÎ¯Î±

- **`train_decision_tree_titanic.py`**  
  Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î´Î­Î½Ï„ÏÎ¿Ï… Î±Ï€Î¿Ï†Î¬ÏƒÎµÏ‰Î½ Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ dataset Ï„Î¿Ï… Titanic.

- **`infer_decision_tree_titanic.py`**  
  Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… ÎºÎ±Î¹ Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· Î³Î¹Î± Î½Î­Î¿ ÎµÏ€Î¹Î²Î¬Ï„Î·.

- **`impurity_measures_mushrooms.py`**  
  Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Entropy, Split Information, Gain Ratio ÎºÎ±Î¹ Gini Gain
  Î³Î¹Î± ÎºÎ¬Î¸Îµ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏŒ Ï„Î¿Ï… dataset Î¼Îµ Ï„Î± Î¼Î±Î½Î¹Ï„Î¬ÏÎ¹Î± (Mushroom dataset).

- **`models/`**  
  Î ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Ï„Î± ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î± (`.joblib`) ÎºÎ±Î¹, Î±Î½ Ï„Î¿ Î´Î­Î½Ï„ÏÎ¿ ÎµÎ¯Î½Î±Î¹ ÏÎ·Ï‡ÏŒ,
  Ï„Î± Î´Î¹Î±Î³ÏÎ¬Î¼Î¼Î±Ï„Î¬ Ï„Î¿Ï… (`.png`).

---

## ğŸ“Š Î”ÎµÎ´Î¿Î¼Î­Î½Î±

Î‘Î½Î±Î¼ÎµÎ½ÏŒÎ¼ÎµÎ½Î± Î±ÏÏ‡ÎµÎ¯Î± ÏƒÏ„Î¿ Ï†Î¬ÎºÎµÎ»Î¿ `data/` (Î´ÎµÏ‚ `data/README.md`):

- `titanic_train.csv`  â€” Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ (Titanic competition)  
- `mushrooms.csv`      â€” Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Ï„Î¿ Ï€Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± purity measures

---

## âš™ï¸ Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·

```bash
pip install -r requirements.txt
# Î® ÎµÎ½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ¬:
pip install scikit-learn pandas matplotlib joblib
```

---

## ğŸš€ Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Ï„Ï‰Î½ scripts

Î‘Ï€ÏŒ Ï„Î¿Î½ ÏÎ¹Î¶Î¹ÎºÏŒ Ï†Î¬ÎºÎµÎ»Î¿ Ï„Î¿Ï… Î±Ï€Î¿Î¸ÎµÏ„Î·ÏÎ¯Î¿Ï… (ÏŒÏ€Î¿Ï… Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±):

```bash
# 1ï¸âƒ£ Î’Î±ÏƒÎ¹ÎºÎ® ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· (Gini, max_depth=3)
python -m decision_trees.train_decision_tree_titanic --criterion gini --max_depth 3 --test_size 0.2 --random_state 0

# 2ï¸âƒ£ Î›Î¯Î³Î¿ Î²Î±Î¸ÏÏ„ÎµÏÎ¿ Î´Î­Î½Ï„ÏÎ¿ (Gini, max_depth=4)
python -m decision_trees.train_decision_tree_titanic --criterion gini --max_depth 4 --test_size 0.2 --random_state 0

# 3ï¸âƒ£ Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Gini vs Entropy ÏƒÏ„Î¿ Î¯Î´Î¹Î¿ Î²Î¬Î¸Î¿Ï‚
python -m decision_trees.train_decision_tree_titanic --criterion entropy --max_depth 4 --test_size 0.2 --random_state 0

# 4ï¸âƒ£ Î Î¹Î¿ Î²Î±Î¸Ï Î´Î­Î½Ï„ÏÎ¿ (Entropy, max_depth=8) â€” Î±ÏÏ‡Î¯Î¶ÎµÎ¹ Ï„Î¿ overfitting
python -m decision_trees.train_decision_tree_titanic --criterion entropy --max_depth 8 --test_size 0.2 --random_state 0

# 5ï¸âƒ£ Î§Ï‰ÏÎ¯Ï‚ ÏŒÏÎ¹Î¿ Î²Î¬Î¸Î¿Ï…Ï‚ (Gini) â€” ÎµÎ¼Ï†Î±Î½Î­Ï‚ overfitting
python -m decision_trees.train_decision_tree_titanic --criterion gini --test_size 0.2 --random_state 0

# 6ï¸âƒ£ Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½ ÎºÎ±Î¸Î±ÏÏŒÏ„Î·Ï„Î±Ï‚ ÏƒÏ„Î¿ Mushroom dataset
python -m decision_trees.impurity_measures_mushrooms
```

ğŸ’¡ *Î¤Î± Î¼Î¿Î½Ï„Î­Î»Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏÎ¿Î½Ï„Î±Î¹ ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿* `models/`,  
Ï€.Ï‡. `decision_tree_titanic_entropy_depth4.joblib`,  
ÎºÎ±Î¹ Ï„Î± Î´Î¹Î±Î³ÏÎ¬Î¼Î¼Î±Ï„Î± (Î±Î½ depth â‰¤ 4) ÏƒÎµ `.png` Î±ÏÏ‡ÎµÎ¯Î±.

---

## ğŸ” Inference (Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· Î³Î¹Î± Î½Î­Î¿ ÎµÏ€Î¹Î²Î¬Ï„Î·)

```bash
python -m decision_trees.infer_decision_tree_titanic
```

Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ ÎµÎ¬Î½ Î¿ ÎµÏ€Î¹Î²Î¬Ï„Î·Ï‚ Î¸Î± ÎµÏ€Î¹Î²Î¯Ï‰Î½Îµ (1) Î® ÏŒÏ‡Î¹ (0), ÎºÎ±Î¸ÏÏ‚ ÎºÎ±Î¹ Ï„Î¹Ï‚ Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„ÎµÏ‚.

---

## ğŸ„ Impurity measures ÏƒÏ„Î¿ Mushroom dataset

Î¤Î¿ script:

```bash
python -m decision_trees.impurity_measures_mushrooms
```

Î´Î¹Î±Î²Î¬Î¶ÎµÎ¹ Ï„Î¿ `mushrooms.csv` ÎºÎ±Î¹ Î³Î¹Î± ÎºÎ¬Î¸Îµ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏŒ (Ï€.Ï‡. `odor`, `cap-color`, `gill-size`):

- Ï…Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹:
  - **Information Gain** (Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î·Î½ Entropy),
  - **Split Information**,
  - **Gain Ratio** (IG / SplitInfo),
  - **Gini Gain** (Î¼ÎµÎ¯Ï‰ÏƒÎ· Gini impurity),
- ÎºÎ±Î¹ ÎµÎºÏ„Ï…Ï€ÏÎ½ÎµÎ¹ Ï„Î¿Ï…Ï‚ **top-10 â€œÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï…Ï‚â€ predictors** ÏƒÏÎ¼Ï†Ï‰Î½Î± Î¼Îµ ÎºÎ¬Î¸Îµ Î¼Î­Ï„ÏÎ¿:

- `Top features by Information Gain`
- `Top features by Gain Ratio`
- `Top features by Gini Gain`

### Î¤Î¹ Ï€ÎµÏÎ¹Î¼Î­Î½Î¿Ï…Î¼Îµ Î½Î± Î´Î¿ÏÎ¼Îµ

- Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ ÏŒÏ€Ï‰Ï‚ Î· **Î¿ÏƒÎ¼Î® (`odor`)** Ï„ÎµÎ¯Î½Î¿Ï…Î½ Î½Î± Î­Ï‡Î¿Ï…Î½ **Ï€Î¿Î»Ï Ï…ÏˆÎ·Î»ÏŒ Information Gain ÎºÎ±Î¹ Gini Gain**,  
  Î³Î¹Î±Ï„Î¯ ÏƒÏ‡ÎµÎ´ÏŒÎ½ Â«ÎºÏŒÎ²Î¿Ï…Î½Â» Ï„Î­Î»ÎµÎ¹Î± Ï†Î±Î³ÏÏƒÎ¹Î¼Î± Î±Ï€ÏŒ Î´Î·Î»Î·Ï„Î·ÏÎ¹ÏÎ´Î· Î¼Î±Î½Î¹Ï„Î¬ÏÎ¹Î±.
- Î¤Î¿ **Gain Ratio** Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î±Î»Î»Î¬Î¾ÎµÎ¹ ÎµÎ»Î±Ï†ÏÎ¬ Ï„Î· ÏƒÎµÎ¹ÏÎ¬ ÎºÎ±Ï„Î¬Ï„Î±Î¾Î·Ï‚, Î³Î¹Î±Ï„Î¯:
  - Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ Ï…Ï€ÏŒÏˆÎ· Ï„Î¿ Ï€ÏŒÏƒÎ¿ Â«Î´Î¹Î±ÏƒÎºÎ¿ÏÏ€Î¹ÏƒÎ¼Î­Î½Î¿Â» ÎµÎ¯Î½Î±Î¹ Ï„Î¿ feature (Ï€ÏŒÏƒÎµÏ‚ ÎºÎ±Î¹ Ï€ÏŒÏƒÎ¿ Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½ÎµÏ‚ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯ÎµÏ‚ Î­Ï‡ÎµÎ¹),
  - Î¬ÏÎ± Î¼ÎµÎ¹ÏÎ½ÎµÎ¹ Ï„Î¿ bias Ï…Ï€Î­Ï Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ Î¼Îµ Ï€Î¿Î»Î»Î­Ï‚ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Ï„Î¹Î¼Î­Ï‚.
- Î£Ï…Î½Î®Î¸Ï‰Ï‚:
  - Î¿Î¹ ÎºÎ¿ÏÏ…Ï†Î±Î¯ÎµÏ‚ ÏƒÏ„Î®Î»ÎµÏ‚ (Ï€.Ï‡. `odor`, `spore-print-color`, `gill-size`)  
    ÎµÎ¼Ï†Î±Î½Î¯Î¶Î¿Î½Ï„Î±Î¹ ÏˆÎ·Î»Î¬ ÏƒÎµ **ÏŒÎ»ÎµÏ‚** Ï„Î¹Ï‚ Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚,
  - Î±Î»Î»Î¬ Î· **Î±ÎºÏÎ¹Î²Î®Ï‚ ÏƒÎµÎ¹ÏÎ¬** ÎºÎ±Î¹ Î¿Î¹ â€œÎ¼ÎµÏƒÎ±Î¯ÎµÏ‚â€ Î¸Î­ÏƒÎµÎ¹Ï‚ Î±Î»Î»Î¬Î¶Î¿Ï…Î½ Î±Î½Î¬Î»Î¿Î³Î± Î¼Îµ Ï„Î¿ Î±Î½ ÎºÎ¿Î¹Ï„Î¬Î¼Îµ **IG**, **Gain Ratio** Î® **Gini Gain**.

Î£Ï„ÏŒÏ‡Î¿Ï‚ Ï„Î¿Ï… script ÎµÎ¯Î½Î±Î¹ Î½Î± Î´Î¿ÏÎ¼Îµ **ÏƒÏ„Î·Î½ Ï€ÏÎ¬Î¾Î·** ÏŒÏ„Î¹:

- Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚ impurity Î´Î¯Î½Î¿Ï…Î½ **ÎµÎ»Î±Ï†ÏÏÏ‚ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ® ÎµÎ¹ÎºÏŒÎ½Î±** Î³Î¹Î± Ï„Î¿ Ï€Î¿Î¹Î± features ÎµÎ¯Î½Î±Î¹ Ï€Î¹Î¿ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¬,  
- ÎºÎ±Î¹ ÏŒÏ„Î¹ Î¼Î­Ï„ÏÎ± ÏŒÏ€Ï‰Ï‚ Ï„Î¿ **Gain Ratio** Ï€ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ½ Î½Î± Î´Î¹Î¿ÏÎ¸ÏÏƒÎ¿Ï…Î½ Î±Î´Ï…Î½Î±Î¼Î¯ÎµÏ‚ Ï„Î¿Ï… Î±Ï€Î»Î¿Ï Information Gain.

---

## ğŸ““ Notebooks

- `notebooks/01_decision_trees_titanic.ipynb`  
  Î’Î®Î¼Î±-Î²Î®Î¼Î± ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·, Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÎºÎ±Î¹ Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· ÏƒÏ„Î¿ Titanic.

- `notebooks/01b_impurity_measures_mushrooms.ipynb`  
  Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ï Entropy, Gain Ratio ÎºÎ±Î¹ Gini Index ÏƒÏ„Î¿ Mushroom dataset,
  ÎºÎ±Î¸ÏÏ‚ ÎºÎ±Î¹ ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ· Î´Î­Î½Ï„ÏÏ‰Î½ Î¼Îµ `criterion="entropy"` vs `criterion="gini"`.

---

## ğŸ¯ Î¤Î¹ Î´ÎµÎ¯Ï‡Î½Î¿Ï…Î½ Î¿Î¹ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ ÏÏ…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚

| Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ | Î•ÏÎ¼Î·Î½ÎµÎ¯Î± |
|-------------|-----------|
| `--criterion gini --max_depth 3` | Î‘Ï€Î»ÏŒ Î´Î­Î½Ï„ÏÎ¿ â€” underfitting |
| `--criterion gini --max_depth 4` | ÎšÎ±Î»Î® Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± (sweet spot) |
| `--criterion entropy --max_depth 4` | Î Î±ÏÏŒÎ¼Î¿Î¹Î± Î±ÎºÏÎ¯Î²ÎµÎ¹Î±, Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ splits |
| `--criterion entropy --max_depth 8` | Overfitting (trainâ†‘, valâ†“) |
| `--criterion gini --max_depth None` | Î Î»Î®ÏÎµÏ‚ overfitting |

---

## ğŸ“ˆ Î‘Î½Î¬Î»Ï…ÏƒÎ· Ï„Ï‰Î½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ (Titanic)

ÎšÎ±Ï„Î¬ ÎºÎ±Î½ÏŒÎ½Î±, Ï„Î¿ Î´Î­Î½Ï„ÏÎ¿ Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ ÏŒÏ„Î¹:

- ÎŸÎ¹ **Î³Ï…Î½Î±Î¯ÎºÎµÏ‚** (`Sex=female`) ÎµÎ¯Ï‡Î±Î½ Ï€Î¿Î»Ï Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ· Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„Î± Î½Î± ÎµÏ€Î¹Î²Î¹ÏÏƒÎ¿Ï…Î½.  
- ÎŸÎ¹ **ÎµÏ€Î¹Î²Î¬Ï„ÎµÏ‚ 1Î·Ï‚ Î¸Î­ÏƒÎ·Ï‚** (`Pclass=1`) ÎµÎ¯Ï‡Î±Î½ ÎµÏ€Î¯ÏƒÎ·Ï‚ Ï…ÏˆÎ·Î»ÏŒÏ„ÎµÏÎ· Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„Î±.  
- ÎŸÎ¹ **ÎµÏ€Î¹Î²Î¬Ï„ÎµÏ‚ Î¼Îµ Ï…ÏˆÎ·Î»ÏŒ ÎµÎ¹ÏƒÎ¹Ï„Î®ÏÎ¹Î¿ (Fare)** ÎµÎ¼Ï†Î¬Î½Î¹Î¶Î±Î½ Î¸ÎµÏ„Î¹ÎºÎ® ÏƒÏ…ÏƒÏ‡Î­Ï„Î¹ÏƒÎ· Î¼Îµ ÎµÏ€Î¹Î²Î¯Ï‰ÏƒÎ·.  
- ÎŸÎ¹ **Î½ÎµÎ±ÏÏŒÏ„ÎµÏÎµÏ‚ Î·Î»Î¹ÎºÎ¯ÎµÏ‚ (Age Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎ·)** Ï„ÎµÎ¯Î½Î¿Ï…Î½ Î½Î± ÎµÏ€Î¹Î²Î¹ÏÎ½Î¿Ï…Î½ ÏƒÏ…Ï‡Î½ÏŒÏ„ÎµÏÎ±.  

Î‘Ï…Ï„Î¬ ÎµÏ€Î¹Î²ÎµÎ²Î±Î¹ÏÎ½Î¿Î½Ï„Î±Î¹:
- ÎµÎ¯Ï„Îµ Î±Ï€ÏŒ Ï„Î· **ÏÎ¯Î¶Î± ÎºÎ±Î¹ Ï„Î± Ï€ÏÏÏ„Î± splits** Ï„Î¿Ï… Î´Î­Î½Ï„ÏÎ¿Ï… (Î¼Îµ Î¼Î¹ÎºÏÏŒ depth=4),
- ÎµÎ¯Ï„Îµ Î±Ï€ÏŒ Ï„Î± **feature importances**:

```python
pipe = joblib.load("models/decision_tree_titanic_entropy_depth4.joblib")
importances = pipe.named_steps["model"].feature_importances_
ohe = pipe.named_steps["preprocess"].named_transformers_["cat"]
cat_feature_names = list(ohe.get_feature_names_out(["Sex", "Embarked"]))
feature_names = cat_feature_names + ["Pclass", "Age", "SibSp", "Parch", "Fare"]
sorted(list(zip(feature_names, importances)), key=lambda x: x[1], reverse=True)
```

Î¤Ï…Ï€Î¹ÎºÎ¬ Î¸Î± Î´ÎµÎ¹Ï‚ ÏŒÏ„Î¹:

- `Sex_*` ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Ï€Î¹Î¿ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏŒ,
- Î±ÎºÎ¿Î»Î¿Ï…Î¸Î¿ÏÎ½ `Pclass`, `Fare`, `Age`.

---

## ğŸ’¬ Î£Ï…Î¼Ï€Î­ÏÎ±ÏƒÎ¼Î±

ÎœÎµ Î±Ï…Ï„ÏŒ Ï„Î¿ module Î¼Ï€Î¿ÏÎ¿ÏÎ¼Îµ Î½Î±:

- ÎµÎºÏ€Î±Î¹Î´ÎµÏÏƒÎ¿Ï…Î¼Îµ ÎºÎ±Î¹ Î½Î± ÎµÏÎ¼Î·Î½ÎµÏÏƒÎ¿Ï…Î¼Îµ Î´Î­Î½Ï„ÏÎ± Î±Ï€Î¿Ï†Î¬ÏƒÎµÏ‰Î½ ÏƒÏ„Î¿ Titanic dataset,
- Î¼ÎµÎ»ÎµÏ„Î®ÏƒÎ¿Ï…Î¼Îµ **overfitting / underfitting** Î¼ÎµÏ„Î±Î²Î¬Î»Î»Î¿Î½Ï„Î±Ï‚ Ï„Î¿ Î²Î¬Î¸Î¿Ï‚,
- ÎºÎ±Ï„Î±Î½Î¿Î®ÏƒÎ¿Ï…Î¼Îµ **Information Gain, Gain Ratio ÎºÎ±Î¹ Gini** ÏƒÏ„Î¿ Mushroom dataset,
- ÎºÎ±Î¹ Î½Î± Î´Î¿ÏÎ¼Îµ Ï€ÏÏ‚ Î¿Î¹ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚ impurity ÎµÏ€Î·ÏÎµÎ¬Î¶Î¿Ï…Î½ Ï„Î·Î½ ÎµÏ€Î¹Î»Î¿Î³Î® Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
  ÎºÎ±Î¹, Ï„ÎµÎ»Î¹ÎºÎ¬, Ï„Î· ÏƒÏ…Î¼Ï€ÎµÏÎ¹Ï†Î¿ÏÎ¬ ÎµÎ½ÏŒÏ‚ decision tree.
