{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b57553e",
   "metadata": {},
   "source": [
    "# Impurity Measures on Mushroom Dataset\n",
    "\n",
    "Σε αυτό το notebook θα δούμε πώς **διαφορετικές μετρικές καθαρότητας** (impurity measures)\n",
    "επηρεάζουν:\n",
    "\n",
    "- την **αξιολόγηση των χαρακτηριστικών** (ποια θεωρούνται πιο σημαντικά)\n",
    "- και έμμεσα τις **επιλογές ενός δέντρου αποφάσεων**.\n",
    "\n",
    "Θα χρησιμοποιήσουμε το *Mushroom Classification* dataset:\n",
    "\n",
    "- Στόχος: `class` (edible `e` ή poisonous `p`)\n",
    "- Χαρακτηριστικά: αποκλειστικά **κατηγορικά** (π.χ. `odor`, `cap-color`, `gill-size`)\n",
    "\n",
    "Μετρικές που θα υπολογίσουμε για κάθε χαρακτηριστικό:\n",
    "\n",
    "- **Entropy / Information Gain**\n",
    "- **Split Information & Gain Ratio**\n",
    "- **Gini Impurity / Gini Gain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dffe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Αν το notebook βρίσκεται στον φάκελο notebooks/, τότε το ROOT είναι ένας κατάλογος πάνω\n",
    "ROOT = Path(\"..\").resolve()\n",
    "DATA_PATH = ROOT / \"data\" / \"mushrooms.csv\"\n",
    "\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52aca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# ΥΠΟΛΟΓΙΣΜΟΣ ENTROPY\n",
    "# ----------------------------------------------\n",
    "def entropy(y: pd.Series) -> float:\n",
    "    \"\"\"Υπολογίζει την εντροπία (entropy) για μια στήλη κατηγορικών τιμών.\n",
    "\n",
    "    Τύπος:\n",
    "        H = - Σ (p_i * log2(p_i))\n",
    "\n",
    "    όπου p_i είναι η σχετική συχνότητα κάθε κατηγορίας.\n",
    "    Αν όλες οι τιμές είναι ίδιες -> H = 0 (τέλεια καθαρότητα)\n",
    "    Αν οι τιμές είναι ισοκατανεμημένες -> H = log2(k) (μέγιστη αβεβαιότητα)\n",
    "    \"\"\"\n",
    "    p = y.value_counts(normalize=True)\n",
    "    return float(-(p * np.log2(p)).sum())\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# ΥΠΟΛΟΓΙΣΜΟΣ GINI IMPURITY\n",
    "# ----------------------------------------------\n",
    "def gini_impurity(y: pd.Series) -> float:\n",
    "    \"\"\"Υπολογίζει την αβεβαιότητα Gini για μια στήλη κατηγορικών τιμών.\n",
    "\n",
    "    Τύπος:\n",
    "        G = 1 - Σ (p_i)^2\n",
    "\n",
    "    Όπου p_i η πιθανότητα κάθε κατηγορίας.\n",
    "    Όσο μικρότερη η G, τόσο πιο \"καθαρός\" ο κόμβος.\n",
    "    \"\"\"\n",
    "    p = y.value_counts(normalize=True)\n",
    "    return float(1.0 - (p**2).sum())\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# ΥΠΟΛΟΓΙΣΜΟΣ ΠΛΗΡΟΦΟΡΙΑΣ ΚΑΙ ΔΕΙΚΤΩΝ ΓΙΑ ΕΝΑ ΧΑΡΑΚΤΗΡΙΣΤΙΚΟ\n",
    "# ----------------------------------------------\n",
    "def feature_scores(df: pd.DataFrame, feature: str, target: str):\n",
    "    \"\"\"\n",
    "    Υπολογίζει 4 δείκτες καθαρότητας για ένα κατηγορικό χαρακτηριστικό:\n",
    "\n",
    "      - Information Gain (IG)\n",
    "      - Split Information\n",
    "      - Gain Ratio\n",
    "      - Gini Gain\n",
    "\n",
    "    Οι δείκτες αυτοί δείχνουν πόσο \"πληροφοριακό\" είναι το χαρακτηριστικό\n",
    "    για την πρόβλεψη της μεταβλητής-στόχου.\n",
    "    \"\"\"\n",
    "\n",
    "    y = df[target]\n",
    "    n = len(df)\n",
    "\n",
    "    # Πριν το split\n",
    "    H_before = entropy(y)\n",
    "    G_before = gini_impurity(y)\n",
    "\n",
    "    # Μετά το split (weighted)\n",
    "    H_after = 0.0\n",
    "    G_after = 0.0\n",
    "    split_info = 0.0\n",
    "\n",
    "    # Για κάθε διαφορετική τιμή του feature\n",
    "    for v, subset in df.groupby(feature):\n",
    "        weight = len(subset) / n\n",
    "        y_sub = subset[target]\n",
    "\n",
    "        H_after += weight * entropy(y_sub)\n",
    "        G_after += weight * gini_impurity(y_sub)\n",
    "\n",
    "        if weight > 0:\n",
    "            split_info -= weight * np.log2(weight)\n",
    "\n",
    "    info_gain = H_before - H_after\n",
    "    gini_gain = G_before - G_after\n",
    "    gain_ratio = info_gain / split_info if split_info > 0 else 0.0\n",
    "\n",
    "    return info_gain, split_info, gain_ratio, gini_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fea302",
   "metadata": {},
   "source": [
    "## 1. Φόρτωση δεδομένων & βασική εξερεύνηση\n",
    "\n",
    "Θα φορτώσουμε το `mushrooms.csv`, θα δούμε τις πρώτες γραμμές και την κατανομή της κλάσης\n",
    "(edible vs poisonous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b3c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Πληροφορίες για τις στήλες\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f9208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Κατανομή της κλάσης-στόχου (edible vs poisonous)\n",
    "df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abd4fc",
   "metadata": {},
   "source": [
    "## 2. Υπολογισμός Information Gain, Gain Ratio και Gini Gain\n",
    "\n",
    "Για κάθε χαρακτηριστικό θα υπολογίσουμε:\n",
    "\n",
    "- **Information Gain**: πόσο μειώνεται η εντροπία αν κάνουμε split σε αυτό το feature.\n",
    "- **Split Information**: πόσο \"διασκορπισμένες\" είναι οι τιμές του feature.\n",
    "- **Gain Ratio**: IG κανονικοποιημένο με βάση το split info (αντισταθμίζει features με πολλές κατηγορίες).\n",
    "- **Gini Gain**: αντίστοιχο του IG αλλά με Gini impurity αντί για entropy.\n",
    "\n",
    "Στόχος: να συγκρίνουμε τη **σειρά σημαντικότητας** των χαρακτηριστικών ανά μετρική.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"class\"  # 'e' ή 'p'\n",
    "features = [c for c in df.columns if c != target]\n",
    "\n",
    "rows = []\n",
    "for feat in features:\n",
    "    ig, si, gr, gg = feature_scores(df, feat, target)\n",
    "    rows.append(\n",
    "        {\n",
    "            \"feature\": feat,\n",
    "            \"num_values\": df[feat].nunique(),\n",
    "            \"info_gain\": ig,\n",
    "            \"split_info\": si,\n",
    "            \"gain_ratio\": gr,\n",
    "            \"gini_gain\": gg,\n",
    "        }\n",
    "    )\n",
    "\n",
    "scores = pd.DataFrame(rows)\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b0f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Top 10 features by Information Gain ===\")\n",
    "display(scores.sort_values(\"info_gain\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\n=== Top 10 features by Gain Ratio ===\")\n",
    "display(scores.sort_values(\"gain_ratio\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\n=== Top 10 features by Gini Gain ===\")\n",
    "display(scores.sort_values(\"gini_gain\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f25f2",
   "metadata": {},
   "source": [
    "### Παρατήρηση\n",
    "\n",
    "Συχνά θα δούμε ότι:\n",
    "\n",
    "- Χαρακτηριστικά όπως η **οσμή (`odor`)** έχουν πολύ υψηλό **Information Gain** και **Gini Gain**,\n",
    "  γιατί διαχωρίζουν σχεδόν τέλεια φαγώσιμα από δηλητηριώδη μανιτάρια.\n",
    "- Το **Gain Ratio** μπορεί να αλλάξει ελαφρώς τη σειρά, επειδή τιμωρεί features με\n",
    "  πάρα πολλές κατηγορίες (ψηλό split info).\n",
    "\n",
    "Έτσι, διαφορετικές μετρικές μπορεί να προτείνουν **διαφορετική \"προτεραιότητα\" χαρακτηριστικών**,  \n",
    "ειδικά όταν κάποια έχουν πολλές μοναδικές τιμές.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d75eb",
   "metadata": {},
   "source": [
    "## 3. Δέντρα αποφάσεων με διαφορετικά κριτήρια (entropy vs gini)\n",
    "\n",
    "Τώρα θα εκπαιδεύσουμε δύο δέντρα αποφάσεων:\n",
    "\n",
    "- Ένα με **criterion = \"entropy\"**\n",
    "- Ένα με **criterion = \"gini\"**\n",
    "\n",
    "και θα συγκρίνουμε:\n",
    "\n",
    "- την απόδοση (accuracy),\n",
    "- τις **feature importances**.\n",
    "\n",
    "Έτσι θα δούμε στην πράξη πώς οι διαφορετικές μετρικές impurity\n",
    "επηρεάζουν το ποια χαρακτηριστικά θεωρούνται πιο σημαντικά από το μοντέλο.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edc9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Όλα τα features είναι κατηγορικά -> τα κωδικοποιούμε με one-hot\n",
    "X = pd.get_dummies(df.drop(columns=[target]))\n",
    "y = (df[target] == 'p').astype(int)  # 1 = poisonous, 0 = edible\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0, stratify=y\n",
    ")\n",
    "\n",
    "def train_tree(criterion):\n",
    "    clf = DecisionTreeClassifier(criterion=criterion, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return clf, acc\n",
    "\n",
    "tree_entropy, acc_entropy = train_tree(\"entropy\")\n",
    "tree_gini, acc_gini = train_tree(\"gini\")\n",
    "\n",
    "print(f\"Accuracy (entropy): {acc_entropy:.3f}\")\n",
    "print(f\"Accuracy (gini):    {acc_gini:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28bba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Συγκρίνουμε τις 10 πιο σημαντικές μεταβλητές για κάθε κριτήριο\n",
    "fi_entropy = pd.Series(tree_entropy.feature_importances_, index=X.columns)\n",
    "fi_gini = pd.Series(tree_gini.feature_importances_, index=X.columns)\n",
    "\n",
    "print(\"=== Top 10 features (entropy) ===\")\n",
    "display(fi_entropy.sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\n=== Top 10 features (gini) ===\")\n",
    "display(fi_gini.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17be2be6",
   "metadata": {},
   "source": [
    "### Συμπεράσματα\n",
    "\n",
    "- Και τα δύο κριτήρια (**entropy** και **gini**) τείνουν να διαλέγουν\n",
    "  τα **ίδια πολύ δυνατά χαρακτηριστικά** (π.χ. `odor_*`).\n",
    "- Οι **ακριβείς σημαντικότητες** (feature importances) και η σειρά κατάταξης\n",
    "  μπορεί να διαφέρουν λίγο, επειδή η κάθε μετρική \"μετράει\" την ακαθαρσία\n",
    "  με διαφορετικό τρόπο.\n",
    "- Σε δεδομένα σαν τα μανιτάρια, όπου κάποια features είναι *πολύ ξεκάθαρα*,\n",
    "  οι διαφορές μεταξύ entropy/gini στην πράξη είναι μικρές.\n",
    "\n",
    "Παρόλα αυτά, η θεωρητική διαφορά στις μετρικές (Information Gain, Gain Ratio, Gini)\n",
    "παίζει ρόλο στην επιλογή splits, ειδικά όταν υπάρχουν πολλαπλά features\n",
    "με παρόμοια discriminative δύναμη.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
