{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Ridge και Lasso Regression με το dataset House Prices (Kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "\n",
    "## Θεωρία: Ridge & Lasso Regularization\n",
    "\n",
    "Για να μειώσουμε την αστάθεια και το overfitting, προσθέτουμε όρους regularization στη συνάρτηση κόστους. Γενικά:\n",
    "$$\n",
    "\\text{Loss} = \\frac{1}{n}\\lVert \\mathbf{y} - X\\boldsymbol{\\beta} \\rVert_2^2 + \\alpha\\,R(\\boldsymbol{\\beta})\n",
    "$$\n",
    "Όπου $\\alpha>0$ ελέγχει τη αυστηρότητα της ποινής.\n",
    "\n",
    "- Ridge (L2): $R(\\boldsymbol{\\beta})=\\lVert\\boldsymbol{\\beta}\\rVert_2^2 = \\sum_j \\beta_j^2$\n",
    "  $$\\min_{\\boldsymbol{\\beta}}\\; \\frac{1}{n}\\lVert \\mathbf{y} - X\\boldsymbol{\\beta} \\rVert_2^2 + \\alpha \\sum_j \\beta_j^2$$\n",
    "  Κλειστή λύση: $\\boldsymbol{\\beta}_{\\text{Ridge}}=(X^\\top X + \\alpha I)^{-1} X^\\top \\mathbf{y}$\n",
    "- Lasso (L1): $R(\\boldsymbol{\\beta})=\\lVert\\boldsymbol{\\beta}\\rVert_1 = \\sum_j |\\beta_j|$\n",
    "  $$\\min_{\\boldsymbol{\\beta}}\\; \\frac{1}{n}\\lVert \\mathbf{y} - X\\boldsymbol{\\beta} \\rVert_2^2 + \\alpha \\sum_j |\\beta_j|$$\n",
    "  Προάγει αραιότητα (αρκετοί συντελεστές γίνονται 0).\n",
    "\n",
    "Ερμηνεία του $\\alpha$:\n",
    "- Μικρό $\\alpha$ → κοντά στην OLS → πιθανό overfitting.\n",
    "- Μεγάλο $\\alpha$ → έντονο shrinkage → underfitting.\n",
    "- Ενδιάμεσο $\\alpha$ → ισορροπία bias/variance και καλύτερη γενίκευση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Φόρτωση και προετοιμασία δεδομένων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path('..')\n",
    "DATA_PATH = ROOT / 'data' / 'house_prices_train.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "feature_names = [\n",
    "    'LotArea',\n",
    "    'OverallQual',\n",
    "    'OverallCond',\n",
    "    'YearBuilt',\n",
    "    'GrLivArea',\n",
    "    'BedroomAbvGr',\n",
    "    'GarageCars',\n",
    "]\n",
    "target_name = 'SalePrice'\n",
    "\n",
    "df_model = df[feature_names + [target_name]].copy()\n",
    "df_model = df_model.dropna(subset=[target_name])\n",
    "df_model[feature_names] = df_model[feature_names].fillna(\n",
    "    df_model[feature_names].median()\n",
    ")\n",
    "\n",
    "X = df_model[feature_names]\n",
    "y = df_model[target_name]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. Σύγκριση Linear, Ridge, Lasso για συγκεκριμένα `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    return {'model': name, 'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Linear': Pipeline([('scaler', StandardScaler()), ('model', LinearRegression())]),\n",
    "    'Ridge (α=1.0)': Pipeline([('scaler', StandardScaler()), ('model', Ridge(alpha=1.0, random_state=0))]),\n",
    "    'Lasso (α=0.1)': Pipeline([('scaler', StandardScaler()), ('model', Lasso(alpha=0.1, random_state=0))]),\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, pipe in models.items():\n",
    "    stats = evaluate_model(name, pipe, X_train, y_train, X_test, y_test)\n",
    "    results.append(stats)\n",
    "\n",
    "results_df = pd.DataFrame(results).set_index('model')\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Ερμηνεία\n",
    "\n",
    "1) `results_df` — Σύγκριση Linear / Ridge (α=1) / Lasso (α=0.1):\n",
    "- Δες τις στήλες `MAE`, `RMSE` και `R2` για κάθε μοντέλο στο `results_df`.\n",
    "- Σημείωση από τα τρέχοντα αποτελέσματα: οι τιμές είναι πολύ κοντινές μεταξύ των μοντέλων. Αυτό υποδεικνύει ότι για το συγκεκριμένο σύνολο χαρακτηριστικών και το split train/test, το απλό OLS (Linear) ήδη εξηγεί μεγάλο μέρος της διακύμανσης και η προσθήκη μικρής L2 ή L1 ποινής δεν αλλάζει πολύ το σφάλμα.\n",
    "- Συγκεκριμένα, το RMSE του Ridge (α=1.0) είναι ελαφρώς μικρότερο από το RMSE του Linear — αυτό σημαίνει ότι μικρό shrinkage βοήθησε στη γενίκευση (μικρή μείωση σφάλματος στο test set). Η Lasso με α=0.1 συμπεριφέρεται σχεδόν όπως το Linear σε αυτές τις τιμές (πιθανότατα επειδή οι συντελεστές δεν ήταν αρκετά μεγάλοι ώστε να ‘κοπούν’ σε μηδενικά).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 3. Επίδραση του `alpha` στα Ridge / Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "ridge_rmse = []\n",
    "lasso_rmse = []\n",
    "ridge_coef_mean = []\n",
    "lasso_coef_mean = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Ridge\n",
    "    ridge = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge(alpha=alpha, random_state=0)),\n",
    "    ])\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred_test_ridge = ridge.predict(X_test)\n",
    "    rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_test_ridge))\n",
    "    ridge_rmse.append(rmse_ridge)\n",
    "\n",
    "    ridge_coef = ridge.named_steps['model'].coef_\n",
    "    ridge_coef_mean.append(np.mean(np.abs(ridge_coef)))\n",
    "\n",
    "    # Lasso\n",
    "    lasso = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Lasso(alpha=alpha, random_state=0)),\n",
    "    ])\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred_test_lasso = lasso.predict(X_test)\n",
    "    rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_test_lasso))\n",
    "    lasso_rmse.append(rmse_lasso)\n",
    "\n",
    "    lasso_coef = lasso.named_steps['model'].coef_\n",
    "    lasso_coef_mean.append(np.mean(np.abs(lasso_coef)))\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    {\n",
    "        'alpha': alphas,\n",
    "        'RMSE_Ridge': ridge_rmse,\n",
    "        'RMSE_Lasso': lasso_rmse,\n",
    "        'Mean|coef|_Ridge': ridge_coef_mean,\n",
    "        'Mean|coef|_Lasso': lasso_coef_mean,\n",
    "    }\n",
    ")\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Ερμηνεία\n",
    "\n",
    "1) `summary_df` — Επίδραση του alpha στα Ridge / Lasso (πίνακας με γραμμές για κάθε alpha):\n",
    "- Η στήλη `RMSE_Ridge` δείχνει πώς αλλάζει το RMSE του Ridge καθώς αυξάνουμε το α. Αν παρατηρήσουμε μια μικρή πτώση στο RMSE με μεγαλύτερα α (όπως στα τρέχοντα αποτελέσματα για α=100), αυτό σημαίνει ότι υψηλότερο regularization μείωσε λίγο την υπερεκπαίδευση χωρίς να εισάγει μεγάλο bias — δηλαδή βελτίωσε ελαφρώς την απόδοση στο test set.\n",
    "- Η στήλη `Mean|coef|_Ridge` (μέσο απόλυτο μέγεθος των συντελεστών) δείχνει σαφώς shrinkage: όσο μεγαλώνει το α, τόσο μικραίνει το μέσο απόλυτο μέγεθος των συντελεστών. Αυτό είναι το αναμενόμενο αποτέλεσμα του L2: συρρίκνωση των β.\n",
    "- Στη Lasso βλέπουμε λιγότερη αλλαγή στο RMSE στις δοκιμαζόμενες τιμές α και μικρότερη μείωση στο μέσο απόλυτο μέγεθος των συντελεστών · αυτό συμβαίνει επειδή για αυτές τις συγκεκριμένες τιμές α η L1 ποινή δεν είχε αρκετή ισχύ για να οδηγήσει πολλούς συντελεστές ακριβώς στο 0 (δηλαδή να δημιουργήσει αραιότητα).\n",
    "\n",
    "2) Πρακτικά συμπεράσματα και οδηγίες:\n",
    "- Αν το κύριο μέλημα είναι μικρή βελτίωση στην ακρίβεια πρόβλεψης (RMSE) στο test set, η Ridge με ένα μεσαίο-μεγάλο α μπορεί να βοηθήσει — δείτε πως το RMSE πέφτει ελαφρώς για μεγάλα α στην περίπτωσή μας.\n",
    "- Εάν οι διαφορές μεταξύ Linear, Ridge και Lasso είναι πολύ μικρές (όπως εδώ), τότε προτεραιότητα μπορεί να δοθεί στην απλότητα (Linear) ή στην σταθερότητα (Ridge) ανάλογα με το επιθυμητό trade-off. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-ai (.venv 3.11)",
   "language": "python",
   "name": "adv-ai-venv-3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
