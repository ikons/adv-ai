{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "\n",
    "# Bayesian Learning με Naive Bayes σε SMS Spam dataset\n",
    "\n",
    "Σε αυτό το notebook υλοποιούμε ένα απλό παράδειγμα **Bayesian learning**\n",
    "για ταξινόμηση κειμένου με χρήση του **Multinomial Naive Bayes**.\n",
    "\n",
    "## Στόχοι\n",
    "\n",
    "- Να συνδέσουμε τον τύπο του Bayes με ένα πραγματικό πρόβλημα ταξινόμησης.\n",
    "- Να δούμε πώς η υπόθεση ανεξαρτησίας των χαρακτηριστικών οδηγεί στο Naive Bayes.\n",
    "- Να εκπαιδεύσουμε έναν ταξινομητή για SMS *ham* / *spam* με scikit-learn.\n",
    "- Να παρατηρήσουμε εποπτικά την απόδοση του μοντέλου (confusion matrix, κ.λπ.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Θεωρία: Bayes & Naive Bayes\n",
    "\n",
    "Θυμόμαστε τον τύπο του Bayes:\n",
    "\n",
    "$$\n",
    "P(y \\mid x) = \\frac{P(x \\mid y) P(y)}{P(x)}\n",
    "$$\n",
    "\n",
    "όπου:\n",
    "\n",
    "- $y$ είναι η κλάση (π.χ. $y \\in \\{\\text{ham}, \\text{spam}\\}$),\n",
    "- $x$ είναι το διάνυσμα χαρακτηριστικών (π.χ. οι λέξεις του SMS),\n",
    "- $P(y)$ είναι η **prior** πιθανότητα της κλάσης,\n",
    "- $P(x \\mid y)$ είναι η **likelihood**,\n",
    "- $P(y \\mid x)$ είναι η **posterior** πιθανότητα.\n",
    "\n",
    "Στο **Naive Bayes** υποθέτουμε ότι τα χαρακτηριστικά $x_i$ είναι\n",
    "conditionally independent δεδομένης της κλάσης:\n",
    "\n",
    "$$\n",
    "P(x \\mid y) = \\prod_i P(x_i \\mid y)\n",
    "$$\n",
    "\n",
    "Έτσι, η posterior γράφεται (παραλείποντας το σταθερό $P(x)$):\n",
    "\n",
    "$$\n",
    "P(y \\mid x) \\propto P(y) \\prod_i P(x_i \\mid y)\n",
    "$$\n",
    "\n",
    "Στο σενάριο ταξινόμησης κειμένου, οι $x_i$ αντιστοιχούν σε λέξεις\n",
    "ή n-grams, και το μοντέλο **Multinomial Naive Bayes** χρησιμοποιεί\n",
    "τις συχνότητες εμφάνισης των λέξεων σε κάθε κλάση.\n",
    "\n",
    "> **Σημείωση**: Για λεπτομερέστερη ανάλυση της μετατροπής κειμένου σε αριθμητικά δεδομένα \n",
    "> (Bag-of-Words, TF-IDF, stopwords κλπ.), δες το \n",
    "> [**Bayesian Learning README**](../bayesian_learning/README.md#211-θεωρία-nlp-bag-of-words-λεξιλόγιο--tf-idf) \n",
    "> όπου εξηγούνται αναλυτικά όλες οι τεχνικές NLP που χρησιμοποιούμε.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Βασικά imports για ανάλυση δεδομένων και machine learning\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    ")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "\n",
    "ROOT = Path('..')\n",
    "DATA_PATH = ROOT / 'data' / 'sms_spam.csv'\n",
    "\n",
    "print(f\"Θα φορτώσουμε τα δεδομένα από: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Φόρτωση του dataset sms_spam.csv από τον φάκελο data/\n",
    "# Χρησιμοποιούμε encoding='latin-1' γιατί το αρχείο δεν είναι UTF-8\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, encoding='latin-1')\n",
    "print(f\"Αρχικό σχήμα dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ελέγχουμε τι στήλες υπάρχουν στο DataFrame\n",
    "\n",
    "print(\"Στήλες του DataFrame:\")\n",
    "print(df.columns.tolist())\n",
    "print()\n",
    "print(\"Πρώτες γραμμές:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Βασικός καθαρισμός: αφαιρούμε τις περιττές στήλες και εγγραφές με κενά\n",
    "# Κρατάμε μόνο τις στήλες v1 (label) και v2 (text)\n",
    "df = df[['v1', 'v2']].copy()\n",
    "df.columns = ['label', 'text']  # Μετονομάζουμε για ευκολία\n",
    "df = df.dropna(subset=['label', 'text']).copy()\n",
    "\n",
    "# Κανονικοποίηση labels\n",
    "df['label'] = df['label'].str.strip().str.lower()\n",
    "df = df[df['label'].isin(['ham', 'spam'])].copy()\n",
    "\n",
    "print(f\"Σχήμα μετά τον καθαρισμό (μόνο ham/spam): {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αφαίρεση stopwords (συχνές λέξεις που δεν προσθέτουν πληροφορία)\n",
    "# Π.χ. \"the\", \"a\", \"is\", \"and\" κλπ.\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "print(\"Παράδειγμα stopwords:\", list(ENGLISH_STOP_WORDS)[:20])\n",
    "print(f\"Σύνολο stopwords: {len(ENGLISH_STOP_WORDS)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ελέγχουμε την κατανομή των κλάσεων ham / spam\n",
    "\n",
    "class_counts = df[\"label\"].value_counts().sort_index()\n",
    "print(\"Κατανομή κλάσεων:\")\n",
    "print(class_counts)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(class_counts.index, class_counts.values)\n",
    "ax.set_title(\"Κατανομή κλάσεων στο SMS Spam dataset\")\n",
    "ax.set_xlabel(\"Κλάση\")\n",
    "ax.set_ylabel(\"Πλήθος μηνυμάτων\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Αξιολόγηση Μοντέλου: Μετρικές & Confusion Matrix\n",
    "\n",
    "Όταν εκπαιδεύουμε ένα ταξινομητή (π.χ. για ham / spam), δεν μας αρκεί να ξέρουμε ότι\n",
    "«δουλεύει καλά». Θέλουμε να μετρήσουμε **πόσο καλά** τα πάει και **τι είδους λάθη** κάνει.\n",
    "\n",
    "Σε αυτή την ενότητα θα δούμε:\n",
    "\n",
    "1. Την **confusion matrix** και τη βασική ορολογία (TP, FP, TN, FN).\n",
    "2. Πώς από αυτά τα μεγέθη προκύπτουν οι μετρικές **Precision**, **Recall**, **F1-score** και **Support**.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Confusion Matrix και βασικές έννοιες\n",
    "\n",
    "Ας υποθέσουμε ότι έχουμε ένα πρόβλημα δύο κλάσεων:\n",
    "\n",
    "- **spam** = θετική κλάση (positive)\n",
    "- **ham**  = αρνητική κλάση (negative)\n",
    "\n",
    "Το μοντέλο μας, για κάθε μήνυμα, κάνει μια πρόβλεψη (spam ή ham), που μπορεί να είναι σωστή ή λάθος.\n",
    "Συγκρίνοντας τις **προβλέψεις** με τις **πραγματικές ετικέτες**, μπορούμε να μετρήσουμε:\n",
    "\n",
    "- **TP (True Positive)**: Μηνύματα που ήταν spam και το μοντέλο τα πρόβλεψε ως spam.\n",
    "- **TN (True Negative)**: Μηνύματα που ήταν ham και το μοντέλο τα πρόβλεψε ως ham.\n",
    "- **FP (False Positive)**: Μηνύματα που ήταν ham αλλά το μοντέλο τα πρόβλεψε ως spam (*false alarm*).\n",
    "- **FN (False Negative)**: Μηνύματα που ήταν spam αλλά το μοντέλο τα πρόβλεψε ως ham (*χαμένα spam*).\n",
    "\n",
    "Αυτά τα τέσσερα μεγέθη οργανώνονται στον **confusion matrix**:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\text{TN} & \\text{FP} \\\\\n",
    "\\text{FN} & \\text{TP}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "- Τα διαγώνια στοιχεία (TN, TP) είναι οι **σωστές προβλέψεις**.\n",
    "- Τα μη διαγώνια στοιχεία (FP, FN) είναι τα **λάθη** του μοντέλου.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Μετρικές ταξινόμησης\n",
    "\n",
    "Χρησιμοποιώντας τα TP, FP, TN, FN μπορούμε να ορίσουμε διάφορες μετρικές.\n",
    "Για το spam filtering, μας ενδιαφέρει κυρίως η απόδοση ως προς την κλάση **spam** (θετική κλάση).\n",
    "\n",
    "#### 2.1 Precision (Ακρίβεια θετικών προβλέψεων)\n",
    "\n",
    "Η **Precision** απαντάει στην ερώτηση:\n",
    "\n",
    "> Από όλα τα μηνύματα που το μοντέλο χαρακτήρισε ως *spam*, πόσα ήταν πράγματι spam;\n",
    "\n",
    "Με βάση τα TP και FP ορίζεται ως:\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "- Υψηλή Precision σημαίνει ότι όταν το μοντέλο λέει «spam», **σπάνια κάνει λάθος**.\n",
    "- Είναι σημαντική όταν θέλουμε να αποφύγουμε τα **false positives** (να μην μπλοκάρουμε κανονικά μηνύματα).\n",
    "- Παράδειγμα: Αν Precision=0.95, σημαίνει ότι το 95% των μηνυμάτων που προβλέψαμε ως spam ήταν πραγματικά spam.\n",
    "\n",
    "#### 2.2 Recall (Ανάκληση / Ευαισθησία)\n",
    "\n",
    "Η **Recall** απαντάει στην ερώτηση:\n",
    "\n",
    "> Από όλα τα μηνύματα που ήταν πράγματι *spam*, πόσα κατάφερε να βρει το μοντέλο;\n",
    "\n",
    "Ορίζεται ως:\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "- Υψηλή Recall σημαίνει ότι **δεν χάνουμε πολλά spam** (λίγα FN).\n",
    "- Είναι σημαντική όταν μας ενδιαφέρει να εντοπίσουμε **όσο το δυνατόν περισσότερα** spam μηνύματα.\n",
    "- Παράδειγμα: Αν Recall=0.92, σημαίνει ότι βρήκαμε το 92% από όλα τα αληθινά spam μηνύματα.\n",
    "\n",
    "\n",
    "#### 2.3 F1-score\n",
    "\n",
    "Συχνά θέλουμε **ένα ενιαίο νούμερο** που να συνδυάζει και την Precision και την Recall.\n",
    "Ο **F1-score** είναι ο **αρμονικός μέσος** των Precision και Recall:\n",
    "\n",
    "$$\n",
    "\\text{F1} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "Ιδιότητες:\n",
    "\n",
    "- Παίρνει τιμές από 0 έως 1.\n",
    "- Είναι υψηλός μόνο όταν είναι υψηλές **και** η Precision **και** η Recall.\n",
    "- Χρήσιμος όταν θέλουμε ένα **ισορροπημένο μέτρο** απόδοσης.\n",
    "\n",
    "#### 2.4 Support\n",
    "\n",
    "Το **support** δεν είναι «ποιότητα» του μοντέλου, αλλά απλά:\n",
    "\n",
    "> το πλήθος των παραδειγμάτων κάθε κλάσης στο **validation set** (ή test set).\n",
    "\n",
    "Στο `classification_report` της scikit-learn θα δεις για κάθε κλάση:\n",
    "\n",
    "- Precision  \n",
    "- Recall  \n",
    "- F1-score  \n",
    "- Support  → πόσα δείγματα αυτής της κλάσης υπήρχαν στο σύνολο αξιολόγησης.\n",
    "\n",
    "Το support σε βοηθά να κρίνεις **πόσο αξιόπιστες** είναι οι μετρικές μιας κλάσης  \n",
    "(π.χ. F1-score σε μια κλάση με μόνο 3 δείγματα δεν είναι πολύ σταθερό μέτρο).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Πώς τα χρησιμοποιούμε στην πράξη;\n",
    "\n",
    "1. Φτιάχνουμε προβλέψεις του μοντέλου σε ένα **validation set** (ή test set).  \n",
    "2. Υπολογίζουμε TP, FP, TN, FN → σχηματίζουμε τον **confusion matrix**.  \n",
    "3. Από αυτά υπολογίζουμε:\n",
    "   - Precision (για το spam),\n",
    "   - Recall (για το spam),\n",
    "   - F1-score,\n",
    "   - και βλέπουμε το support κάθε κλάσης.\n",
    "4. Συγκρίνουμε διαφορετικά μοντέλα ή διαφορετικές ρυθμίσεις (π.χ. τιμές του $\\alpha$)\n",
    "   με βάση αυτές τις μετρικές, για να διαλέξουμε την παραμετροποίηση με την καλύτερη συνολική συμπεριφορά.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Συνοπτικά μέτρα: accuracy, macro avg, weighted avg\n",
    "\n",
    "Εκτός από τις μετρικές ανά κλάση (precision, recall, F1, support), το `classification_report` της scikit-learn\n",
    "εμφανίζει και συνοπτικά μέτρα για όλο το μοντέλο: **accuracy**, **macro avg** και **weighted avg**.\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "Η **accuracy** (συνολική ακρίβεια) μετράει ποιο ποσοστό των δειγμάτων ταξινομήθηκε σωστά:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "- Αριθμητής: όλα τα **σωστά** (True Positives + True Negatives).\n",
    "- Παρονομαστής: **όλα** τα δείγματα (σωστά + λάθη).\n",
    "- Δείχνει «πόσο συχνά έχει δίκιο» συνολικά το μοντέλο, χωρίς να ξεχωρίζει κλάσεις.\n",
    "\n",
    "#### macro avg\n",
    "\n",
    "Για κάθε μετρική (π.χ. precision ή recall ή F1) μπορούμε να υπολογίσουμε πρώτα την τιμή της **ανά κλάση**,\n",
    "π.χ. $ m_1, m_2, \\dots, m_K $ για $ K $ κλάσεις, και μετά τον **απλό μέσο όρο**:\n",
    "\n",
    "$$\n",
    "m_{\\text{macro}} = \\frac{1}{K} \\sum_{k=1}^{K} m_k\n",
    "$$\n",
    "\n",
    "- Κάθε κλάση έχει **ίσο βάρος**, ανεξάρτητα από το πόσα δείγματα έχει.\n",
    "- Χρήσιμο όταν μας ενδιαφέρει η **μέση απόδοση ανά κλάση**, π.χ. να μη «θυσιάζουμε» μια μικρή κλάση.\n",
    "\n",
    "Στο `classification_report`, το `macro avg` δίνεται χωριστά για precision, recall και F1-score.\n",
    "\n",
    "#### weighted avg\n",
    "\n",
    "Ο **weighted avg** είναι κι αυτός μέσος όρος πάνω στις κλάσεις, αλλά τώρα κάθε κλάση\n",
    "ζυγίζεται με βάση το **support** της (πόσα δείγματα έχει).\n",
    "\n",
    "Αν \\( \\text{support}_k \\) είναι το πλήθος δειγμάτων της κλάσης \\( k \\) και \\( N = \\sum_k \\text{support}_k \\)\n",
    "είναι το σύνολο των δειγμάτων, τότε για μια μετρική \\( m_k \\) ανά κλάση:\n",
    "\n",
    "$$\n",
    "m_{\\text{weighted}} = \\frac{1}{N} \\sum_{k=1}^{K} m_k \\cdot \\text{support}_k\n",
    "$$\n",
    "\n",
    "- Κλάσεις με **πολλά δείγματα** επηρεάζουν περισσότερο το weighted avg.\n",
    "- Κλάσεις με **λίγα δείγματα** επηρεάζουν λιγότερο.\n",
    "\n",
    "Στο `classification_report`, το `weighted avg` δείχνει την «μέση» συμπεριφορά του μοντέλου\n",
    "με βάση το **πόσα δείγματα** έχει κάθε κλάση (δηλαδή πιο κοντά στο τι συμβαίνει «ανά δείγμα»),\n",
    "ενώ το `macro avg` είναι πιο κοντά σε μέση απόδοση «ανά κλάση».\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Χωρίζουμε τα δεδομένα σε train / validation και εκπαιδεύουμε μοντέλο\n",
    "\n",
    "# Εξάγουμε τα κείμενα (features) για το X\n",
    "X = df[\"text\"]\n",
    "\n",
    "# Εξάγουμε τις ετικέτες και τις μετατρέπουμε σε 0/1\n",
    "# (df[\"label\"] == \"spam\") δημιουργεί True/False\n",
    "# astype(int) μετατρέπει True→1, False→0\n",
    "y = (df[\"label\"] == \"spam\").astype(int)  # 1 = spam, 0 = ham\n",
    "\n",
    "# Χωρίζουμε τα δεδομένα σε train (80%) και validation (20%)\n",
    "# test_size=0.2 σημαίνει 20% για validation, 80% για train\n",
    "# random_state=0 κάνει το χώρισμα αναπαράξιμο (ίδιο κάθε φορά που το τρέχουμε)\n",
    "# stratify=y διασφαλίζει ότι και στα δύο σύνολα υπάρχει ίδια αναλογία ham/spam\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "# Εκτυπώνουμε τα μεγέθη των δύο συνόλων\n",
    "print(\"Μέγεθος train:\", X_train.shape[0])\n",
    "print(\"Μέγεθος validation:\", X_val.shape[0])\n",
    "\n",
    "# Δημιουργούμε ένα Pipeline που συνδυάζει δύο βήματα:\n",
    "# 1. TfidfVectorizer: μετατρέπει κείμενο σε TF-IDF features (αριθμητικές τιμές)\n",
    "#    - max_features=10000: κρατάμε τις 10000 πιο συχνές λέξεις\n",
    "#    - stop_words='english': αφαιρούμε τις συχνές αγγλικές λέξεις (the, a, is, κλπ)\n",
    "# 2. MultinomialNB: ο ταξινομητής Naive Bayes\n",
    "#    - alpha=1.0: παράμετρος εξομάλυνσης Laplace\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"tfidf\", TfidfVectorizer(max_features=10000, stop_words='english')),\n",
    "        (\"clf\", MultinomialNB(alpha=1.0)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Εκπαιδεύουμε το pipeline στο training set\n",
    "# pipe.fit() μαθαίνει το TF-IDF και το Naive Bayes από τα training δεδομένα\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Προβλέπουμε τα labels για το validation set\n",
    "# Κάθε κείμενο στο X_val ταξινομείται ως 0 (ham) ή 1 (spam)\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "print(\"\\nΤο μοντέλο έχει εκπαιδευτεί. Στη συνέχεια θα δούμε τα αποτελέσματα.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αποτελέσματα ταξινόμησης: Precision, Recall, F1-Score\n",
    "\n",
    "# Εκτυπώνουμε λεπτομερή αποτελέσματα ταξινόμησης\n",
    "# classification_report δείχνει precision, recall, f1-score για κάθε κλάση\n",
    "# target_names=[\"ham\", \"spam\"] δίνει ονόματα στις κλάσεις\n",
    "# digits=3 εμφανίζει 3 δεκαδικά ψηφία\n",
    "print(\"=\" * 60)\n",
    "print(\"Classification Report (validation set)\")\n",
    "print(\"=\" * 60)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_val,\n",
    "        y_val_pred,\n",
    "        target_names=[\"ham\", \"spam\"],\n",
    "        digits=3,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Confusion matrix για να δούμε αναλυτικά τις σωστές / λανθασμένες προβλέψεις\n",
    "\n",
    "# Υπολογίζουμε τον confusion matrix\n",
    "# cm[i, j] = πλήθος δειγμάτων που ανήκουν στην κλάση i αλλά προβλέφθηκαν ως κλάση j\n",
    "# labels=[0, 1] σημαίνει: 0=ham (σειρά/στήλη 0), 1=spam (σειρά/στήλη 1)\n",
    "cm = confusion_matrix(y_val, y_val_pred, labels=[0, 1])\n",
    "\n",
    "# Δημιουργούμε αντικείμενο ConfusionMatrixDisplay για την οπτικοποίηση\n",
    "# display_labels=[\"ham\", \"spam\"] θα μπουν ως ετικέτες στο διάγραμμα\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"ham\", \"spam\"])\n",
    "\n",
    "# Δημιουργούμε ένα νέο σχήμα matplotlib με ένα subplot\n",
    "# fig = το σχήμα (παράθυρο), ax = ο άξονας (χώρος σχεδίασης)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Σχεδιάζουμε τον confusion matrix\n",
    "# ax=ax προσδιορίζει που θα σχεδιαστεί\n",
    "# values_format=\"d\" σημαίνει ότι οι τιμές εμφανίζονται ως ακέραιοι (integers)\n",
    "disp.plot(ax=ax, values_format=\"d\")\n",
    "\n",
    "# Προσθέτουμε τίτλο στο διάγραμμα\n",
    "ax.set_title(\"Confusion Matrix (validation set)\")\n",
    "\n",
    "# Προσαρμόζουμε τα περιθώρια του σχήματος για καλύτερη εμφάνιση\n",
    "plt.tight_layout()\n",
    "\n",
    "# Εμφανίζουμε το διάγραμμα\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Παρατηρούμε τις πιο «χαρακτηριστικές» λέξεις για κάθε κλάση\n",
    "\n",
    "# Εξάγουμε τον TF-IDF vectorizer από το pipeline (μετατρέπει κείμενο σε αριθμούς)\n",
    "tfidf = pipe.named_steps[\"tfidf\"]\n",
    "\n",
    "# Εξάγουμε τον Naive Bayes ταξινομητή από το pipeline\n",
    "clf = pipe.named_steps[\"clf\"]\n",
    "\n",
    "# Λαμβάνουμε τα ονόματα όλων των χαρακτηριστικών (λέξεων)\n",
    "# get_feature_names_out() επιστρέφει τις λέξεις που εμφανίζονται στα δεδομένα\n",
    "feature_names = np.array(tfidf.get_feature_names_out())\n",
    "\n",
    "# Λαμβάνουμε τις log-πιθανότητες κάθε λέξης για κάθε κλάση\n",
    "# shape: (2, n_features) όπου [0]=ham, [1]=spam\n",
    "# feature_log_prob_[0] = log P(λέξη | ham)\n",
    "# feature_log_prob_[1] = log P(λέξη | spam)\n",
    "log_probs = clf.feature_log_prob_\n",
    "\n",
    "# Αριθμός top λέξεων που θέλουμε να δούμε\n",
    "top_n = 20\n",
    "\n",
    "# Βρίσκουμε τις indices των 20 λέξεων με τη μεγαλύτερη πιθανότητα στο spam\n",
    "# argsort()[::-1] ταξινομεί από μικρό προς μεγάλο, [::-1] αντιστρέφει σε φθίνουσα σειρά\n",
    "spam_top_idx = np.argsort(log_probs[1])[::-1][:top_n]\n",
    "\n",
    "# Βρίσκουμε τις indices των 20 λέξεων με τη μεγαλύτερη πιθανότητα στο ham\n",
    "ham_top_idx = np.argsort(log_probs[0])[::-1][:top_n]\n",
    "\n",
    "# Εκτυπώνουμε τις λέξεις που χαρακτηρίζουν περισσότερο το spam\n",
    "# Χρησιμοποιούμε feature_names[spam_top_idx] για να πάρουμε τα ονόματα των λέξεων\n",
    "print(\"Top λέξεις για την κλάση 'spam':\")\n",
    "print(feature_names[spam_top_idx])\n",
    "\n",
    "# Εκτυπώνουμε τις λέξεις που χαρακτηρίζουν περισσότερο το ham\n",
    "print(\"\\nTop λέξεις για την κλάση 'ham':\")\n",
    "print(feature_names[ham_top_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Πειραματισμός με την παράμετρο εξομάλυνσης alpha\n",
    "# Σημαντικό: Χρησιμοποιούμε την ίδια ρύθμιση TfidfVectorizer όπως και το αρχικό μοντέλο\n",
    "# (με stop_words='english') για να έχουμε δίκαιη σύγκριση\n",
    "\n",
    "alphas = [0.01, 0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    pipe_a = Pipeline(\n",
    "        steps=[\n",
    "            (\"tfidf\", TfidfVectorizer(max_features=10000, stop_words='english')),\n",
    "            (\"clf\", MultinomialNB(alpha=alpha)),\n",
    "        ]\n",
    "    )\n",
    "    pipe_a.fit(X_train, y_train)\n",
    "    y_val_pred_a = pipe_a.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_val_pred_a)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_val,\n",
    "        y_val_pred_a,\n",
    "        average=\"binary\",\n",
    "        pos_label=1,\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    results.append((alpha, acc, prec, rec, f1))\n",
    "\n",
    "alpha_results = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"alpha\", \"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
    ")\n",
    "alpha_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Εξομάλυνση Laplace (Alpha Parameter) στο Multinomial Naive Bayes\n",
    "\n",
    "### Τι είναι το Alpha;\n",
    "\n",
    "Στο **Multinomial Naive Bayes**, υπολογίζουμε τις πιθανότητες κάθε λέξης σε κάθε κλάση:\n",
    "\n",
    "$$\n",
    "P(x_i \\mid y) = \\frac{\\text{count of word } i \\text{ in class } y}{\\text{total words in class } y}\n",
    "$$\n",
    "\n",
    "**Πρόβλημα**: Τι συμβαίνει αν μια λέξη **δεν εμφανίζεται ποτέ** σε ένα training set αλλά εμφανίζεται σε ένα νέο μήνυμα;\n",
    "Τότε θα έχουμε $P(x_i \\mid y) = 0$, και ολόκληρη η posterior πιθανότητα γίνεται μηδέν!\n",
    "Αυτό είναι πολύ αυστηρό και μη ρεαλιστικό.\n",
    "\n",
    "Η **εξομάλυνση Laplace** (Laplace smoothing) με παράμετρο $\\alpha$ αντιμετωπίζει αυτό το πρόβλημα προσθέτοντας έναν μικρό αριθμό στους μετρητές:\n",
    "\n",
    "$$\n",
    "P(x_i \\mid y) = \\frac{\\text{count of word } i \\text{ in class } y + \\alpha}{\\text{total words in class } y + \\alpha \\cdot V}\n",
    "$$\n",
    "\n",
    "όπου $V$ είναι το μέγεθος του λεξιλογίου (πλήθος μοναδικών λέξεων).\n",
    "\n",
    "**Ερμηνεία**:\n",
    "\n",
    "- **$\\alpha = 0$** (χωρίς εξομάλυνση): Αν μια λέξη δεν εμφανίζεται σε μια κλάση, η πιθανότητα της είναι 0.\n",
    "  Αυτό έχει ως αποτέλεσμα φτωχή γενίκευση σε νέα δεδομένα.\n",
    "\n",
    "- **$\\alpha$ μεγάλο** (π.χ. $\\alpha = 10$): Δίνουμε πολύ μεγάλο βάρος στην εξομάλυνση.\n",
    "  Όλες οι λέξεις γίνονται περισσότερο ισοδύναμες, και το μοντέλο γίνεται πιο \"συντηρητικό\".\n",
    "  Κάνει λιγότερο χρήση των πληροφοριών που πραγματικά υπάρχουν στα δεδομένα.\n",
    "\n",
    "- **$\\alpha$ μικρό** (π.χ. $\\alpha = 0.01$): Δίνουμε μικρό βάρος στην εξομάλυνση.\n",
    "  Το μοντέλο βασίζεται περισσότερο στις πραγματικές συχνότητες του training set.\n",
    "  Αλλά κινδυνεύει να \"overfittάρει\" (να θυμάται τα δεδομένα αντί να μαθαίνει γενικούς κανόνες).\n",
    "\n",
    "---\n",
    "\n",
    "### Γιατί βλέπουμε αυτά τα αποτελέσματα;\n",
    "\n",
    "Ας δούμε τα δεδομένα από το πείραμα (με `stop_words='english'`):\n",
    "\n",
    "| alpha | accuracy | precision | recall | f1 |\n",
    "|-------|----------|-----------|--------|-----|\n",
    "| 0.01  | 0.9758   | 0.9357    | 0.8792 | 0.9066 |\n",
    "| 0.10  | 0.9776   | 0.9559    | 0.8725 | 0.9123 |\n",
    "| 0.50  | 0.9794   | 0.9922    | 0.8523 | 0.9170 |\n",
    "| 1.00  | 0.9713   | 1.0000    | 0.7852 | 0.8797 |\n",
    "| 5.00  | 0.8996   | 1.0000    | 0.2483 | 0.3978 |\n",
    "| 10.00 | 0.8673   | 1.0000    | 0.0067 | 0.0133 |\n",
    "\n",
    "**Παρατηρήσεις**:\n",
    "\n",
    "#### 1. **Σε χαμηλό α (0.01 - 0.50): Ισορροπημένη απόδοση**\n",
    "\n",
    "- Η **recall** είναι υψηλή (~0.85-0.88): Το μοντέλο βρίσκει τα περισσότερα spam μηνύματα.\n",
    "- Το **F1-score** είναι υψηλό (~0.91): Καλή συνολική απόδοση.\n",
    "- Αυτά τα αποτελέσματα είναι **ρεαλιστικά** και **πρακτικά** για χρήση.\n",
    "- **Βέλτιστο**: $\\alpha = 0.50$ με F1 = 0.9170 και χαμηλότερα false positives (Precision = 0.9922).\n",
    "\n",
    "**Γιατί;** Ο μικρός $\\alpha$ επιτρέπει στο μοντέλο να **εκμεταλλεύεται τις πραγματικές λέξεις spam** \n",
    "που εμφανίζονται συχνά στα δεδομένα (π.χ. \"winner\", \"prize\", \"free\"). Ταυτόχρονα, η εξομάλυνση \n",
    "εμποδίζει την εντελώς μηδενική πιθανότητα.\n",
    "\n",
    "#### 2. **Σε μεσαίο α (1.00): Precision αυξάνεται, Recall μειώνεται**\n",
    "\n",
    "- Precision = 1.000 (τέλειο): Όλα τα spam που προβλέψαμε ήταν σωστά.\n",
    "- Recall πέφτει δραματικά: Στο 0.7852 (από 0.8792 στο α=0.01).\n",
    "- F1-score = 0.8797: Χειρότερο από τα χαμηλά α.\n",
    "\n",
    "**Γιατί;** Ο αυξημένος $\\alpha$ «εξομαλύνει» τις πιθανότητες των λέξεων, \n",
    "κάνοντας τις διαφορές μεταξύ ham και spam λιγότερο έντονες. \n",
    "Το μοντέλο γίνεται **πιο συντηρητικό** στη διάγνωση spam, αποφεύγει false positives \n",
    "αλλά χάνει πολλά πραγματικά spam (false negatives).\n",
    "\n",
    "#### 3. **Σε μεγάλο α (5.00 - 10.00): Κατάρρευση του μοντέλου**\n",
    "\n",
    "- Recall → 0.2483 (για $\\alpha = 5.0$): Το μοντέλο **δεν βρίσκει σχεδόν καν spam**.\n",
    "- Recall → 0.0067 (για $\\alpha = 10.0$): Το μοντέλο **σχεδόν ποτέ δεν προβλέπει spam**.\n",
    "- F1-score πλησιάζει το 0: Ο ταξινομητής είναι άχρηστος.\n",
    "\n",
    "**Γιατί;** Ο **εξαιρετικά μεγάλος** $\\alpha$ κάνει όλες τις λέξεις ισοδύναμες μεταξύ ham και spam. \n",
    "Η εξομάλυνση γίνεται τόσο ισχυρή που **ακυρώνει** την πληροφορία που εμπεριέχεται στα πραγματικά δεδομένα. \n",
    "Το μοντέλο **δεν μπορεί να διακρίνει** τα δύο.\n",
    "\n",
    "---\n",
    "\n",
    "### Συμπέρασμα: Επιλογή του βέλτιστου α\n",
    "\n",
    "Για αυτό το SMS Spam dataset με `stop_words='english'`:\n",
    "\n",
    "- **Βέλτιστο**: $\\alpha = 0.50$  \n",
    "  F1-score = 0.9170 (υψηλότερο), Precision = 0.9922, Recall = 0.8523.\n",
    "  Συμφωνία: κλάση spam ανιχνεύεται με λογική και περιορίζονται τα false alarms.\n",
    "\n",
    "- **Πολύ καλό**: $\\alpha \\in [0.01, 0.10]$  \n",
    "  F1-score ≈ 0.91, ελαφρώς υψηλότερη recall (~0.88), αλλά περισσότερα false positives.\n",
    "\n",
    "- **Αποδεκτό αλλά όχι βέλτιστο**: $\\alpha = 1.00$  \n",
    "  F1-score = 0.8797, μεσαία απόδοση. Recall πέφτει σημαντικά.\n",
    "\n",
    "- **Κακό**: $\\alpha \\geq 5.00$  \n",
    "  Ο μοντέλος σπάει, recall → 0, F1-score → 0.\n",
    "\n",
    "**Γενικά κανόνια**:\n",
    "\n",
    "- Ξεκινάμε συχνά με **$\\alpha = 1.0$** (η \"απλή\" εξομάλυνση Laplace).\n",
    "- Για αυτό το dataset, η πειραματική εξερεύνηση δείχνει ότι **χαμηλότερα α** (0.01-0.50) δουλεύουν **σημαντικά καλύτερα**.\n",
    "- Η εξέταση του trade-off μεταξύ Precision και Recall είναι **κρίσιμη**: \n",
    "  - Αν θέλουμε υψηλή Recall (να ανιχνεύσουμε όσο περισσότερο spam γίνεται), **χρησιμοποιούμε χαμηλό α** (π.χ. 0.01).\n",
    "  - Αν θέλουμε υψηλή Precision (να αποφύγουμε false alarms), **χρησιμοποιούμε μεσαίο α** (π.χ. 0.50).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Γραφική απεικόνιση F1 σε συνάρτηση με το alpha\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha_results[\"alpha\"], alpha_results[\"f1\"], marker=\"o\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"alpha (log scale)\")\n",
    "ax.set_ylabel(\"F1 score (spam class)\")\n",
    "ax.set_title(\"Επίδραση της παραμέτρου alpha στο F1\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Δοκιμάζουμε το μοντέλο με βέλτιστο alpha σε μερικά νέα μηνύματα\n",
    "# (Χρησιμοποιούμε α=0.01 που έδωσε τα καλύτερα αποτελέσματα: F1=0.925)\n",
    "\n",
    "# Εκπαιδεύουμε ένα νέο μοντέλο με α=0.01\n",
    "pipe_best = Pipeline(\n",
    "    steps=[\n",
    "        (\"tfidf\", TfidfVectorizer(max_features=10000, stop_words='english')),\n",
    "        (\"clf\", MultinomialNB(alpha=0.5)),\n",
    "    ]\n",
    ")\n",
    "pipe_best.fit(X_train, y_train)\n",
    "\n",
    "example_messages = [\n",
    "    \"WINNER!! You have won a 1000$ cash prize. Call now to claim.\",\n",
    "    \"Hey, are we still on for coffee tomorrow?\",\n",
    "    \"FREE entry in 2 a weekly competition to win FA Cup final tickets. Text WIN to 87121 now!\",\n",
    "    \"I'll be there in 10 minutes.\",\n",
    "]\n",
    "\n",
    "X_new = pd.Series(example_messages)\n",
    "y_pred_new = pipe_best.predict(X_new)\n",
    "y_proba_new = pipe_best.predict_proba(X_new)\n",
    "\n",
    "for text, label, proba in zip(example_messages, y_pred_new, y_proba_new):\n",
    "    cls = \"spam\" if label == 1 else \"ham\"\n",
    "    p_ham, p_spam = proba[0], proba[1]\n",
    "\n",
    "    print(\"-\" * 72)\n",
    "    print(\"Μήνυμα:\")\n",
    "    print(text)\n",
    "    print()\n",
    "    print(f\"→ Πρόβλεψη: {cls.upper()}\")\n",
    "    print(f\"   P(ham | x)  = {p_ham:.3f}\")\n",
    "    print(f\"   P(spam | x) = {p_spam:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
